#Setup in Google Colab:

pip install tensorflow tensorflow_datasets matplotlib
import tensorflow as tf
import tensorflow_datasets as tfds
import matplotlib.pyplot as plt

# Load dataset
dataset, info = tfds.load('oxford_iiit_pet:3.*.*', with_info=True)
train = dataset['train']

# Preprocessing function
def preprocess(datapoint):
    input_image = tf.image.resize(datapoint['image'], [256, 256])
    target_image = tf.image.resize(datapoint['segmentation_mask'], [256, 256])
    input_image = tf.cast(input_image, tf.float32) / 255.0
    target_image = tf.cast(target_image, tf.float32) / 255.0
    return input_image, target_image

train = train.map(preprocess).batch(1)

# Load pre-trained pix2pix from TensorFlow Hub
import tensorflow_hub as hub
model = hub.load('https://tfhub.dev/google/pix2pix/hd/1')

for inp, tar in train.take(1):
    prediction = model(inp)
    plt.figure(figsize=(15, 5))
    display_list = [inp[0], tar[0], prediction[0]]
    title = ['Input', 'Target', 'Predicted']

    for i in range(3):
        plt.subplot(1, 3, i+1)
        plt.title(title[i])
        plt.imshow(display_list[i])
        plt.axis('off')
    plt.show()
